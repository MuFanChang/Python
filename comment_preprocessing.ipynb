{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = pickle.load(open(\"group1_message_pickle.txt\", 'rb'))\n",
    "data2 = pickle.load(open(\"group2_message_pickle.txt\", 'rb'))\n",
    "data3 = pickle.load(open(\"group3_message_pickle.txt\", 'rb'))\n",
    "data4 = pickle.load(open(\"group4_message_pickle.txt\", 'rb'))\n",
    "data5 = pickle.load(open(\"group5_message_pickle.txt\", 'rb'))\n",
    "data6 = pickle.load(open(\"group6_message_pickle.txt\", 'rb'))\n",
    "data7 = pickle.load(open(\"group7_message_pickle.txt\", 'rb'))\n",
    "data = pickle.load(open('total_message_pickle.txt','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#å®šç¾©æ–·è©æ–¹å¼\n",
    "dic = {}\n",
    "dic.update(data)\n",
    "def cutcomment(id):\n",
    "    for i in range(0,len(list(data.values())[id])):\n",
    "        content = re.sub(\"[\\s+\\.\\!\\/_,%^*(+\\\"\\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿ?ã€~@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰ï¼‹ï¼ï½ï¼š]+\",\n",
    "                       \"\",list(data.values())[id][i])\n",
    "        words = jieba.lcut(content,cut_all=False)\n",
    "        dic[list(data.keys())[id]].append(words)\n",
    "#è¿´åœˆæ–·è©\n",
    "for i in range(0,len(list(data.keys()))):\n",
    "    dic[list(data.keys())[i]] = []\n",
    "for j in range(0,len(list(data.keys()))):\n",
    "    cutcomment(j)\n",
    "#å­˜å‡ºä¾†\n",
    "f = open('total_message_word.txt', 'wb')\n",
    "output = pickle.dump(dic, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#å®šç¾©æ–·è©æ–¹å¼\n",
    "dic1 = {}\n",
    "dic1.update(data1)\n",
    "def cutcomment(id):\n",
    "    for i in range(0,len(list(data1.values())[id])):\n",
    "        content1 = re.sub(\"[\\s+\\.\\!\\/_,%^*(+\\\"\\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿ?ã€~@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰ï¼‹ï¼ï½ï¼š]+\",\n",
    "                       \"\",list(data1.values())[id][i])\n",
    "        words1 = jieba.lcut(content1,cut_all=False)\n",
    "        dic1[list(data1.keys())[id]].append(words1)\n",
    "#è¿´åœˆæ–·è©\n",
    "for i in range(0,len(list(data1.keys()))):\n",
    "    dic1[list(data1.keys())[i]] = []\n",
    "for j in range(0,len(list(data1.keys()))):\n",
    "    cutcomment(j)\n",
    "#å­˜å‡ºä¾†\n",
    "f = open('group1_message_word.txt', 'wb')\n",
    "output = pickle.dump(dic1, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#å®šç¾©æ–·è©æ–¹å¼\n",
    "dic2 = {}\n",
    "dic2.update(data2)\n",
    "def cutcomment(id):\n",
    "    for i in range(0,len(list(data2.values())[id])):\n",
    "        content2 = re.sub(\"[\\s+\\.\\!\\/_,%^*(+\\\"\\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿ?ã€~@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰ï¼‹ï¼ï½ï¼š]+\",\n",
    "                       \"\",list(data2.values())[id][i])\n",
    "        words2 = jieba.lcut(content2,cut_all=False)\n",
    "        dic2[list(data2.keys())[id]].append(words2)\n",
    "#è¿´åœˆæ–·è©\n",
    "for i in range(0,len(list(data2.keys()))):\n",
    "    dic2[list(data2.keys())[i]] = []\n",
    "for j in range(0,len(list(data2.keys()))):\n",
    "    cutcomment(j)\n",
    "#å­˜å‡ºä¾†\n",
    "f = open('group2_message_word.txt', 'wb')\n",
    "output = pickle.dump(dic2, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#å®šç¾©æ–·è©æ–¹å¼\n",
    "dic3 = {}\n",
    "dic3.update(data3)\n",
    "def cutcomment(id):\n",
    "    for i in range(0,len(list(data3.values())[id])):\n",
    "        content3 = re.sub(\"[\\s+\\.\\!\\/_,%^*(+\\\"\\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿ?ã€~@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰ï¼‹ï¼ï½ï¼š]+\",\n",
    "                       \"\",list(data3.values())[id][i])\n",
    "        words3 = jieba.lcut(content3,cut_all=False)\n",
    "        dic3[list(data3.keys())[id]].append(words3)\n",
    "#è¿´åœˆæ–·è©\n",
    "for i in range(0,len(list(data3.keys()))):\n",
    "    dic3[list(data3.keys())[i]] = []\n",
    "for j in range(0,len(list(data3.keys()))):\n",
    "    cutcomment(j)\n",
    "#å­˜å‡ºä¾†\n",
    "f = open('group3_message_word.txt', 'wb')\n",
    "output = pickle.dump(dic3, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#å®šç¾©æ–·è©æ–¹å¼\n",
    "dic4 = {}\n",
    "dic4.update(data4)\n",
    "def cutcomment(id):\n",
    "    for i in range(0,len(list(data4.values())[id])):\n",
    "        content4 = re.sub(\"[\\s+\\.\\!\\/_,%^*(+\\\"\\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿ?ã€~@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰ï¼‹ï¼ï½ï¼š]+\",\n",
    "                       \"\",list(data4.values())[id][i])\n",
    "        words4 = jieba.lcut(content4,cut_all=False)\n",
    "        dic4[list(data4.keys())[id]].append(words4)\n",
    "#è¿´åœˆæ–·è©\n",
    "for i in range(0,len(list(data4.keys()))):\n",
    "    dic4[list(data4.keys())[i]] = []\n",
    "for j in range(0,len(list(data4.keys()))):\n",
    "    cutcomment(j)\n",
    "#å­˜å‡ºä¾†\n",
    "f = open('group4_message_word.txt', 'wb')\n",
    "output = pickle.dump(dic4, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#å®šç¾©æ–·è©æ–¹å¼\n",
    "dic5 = {}\n",
    "dic5.update(data5)\n",
    "def cutcomment(id):\n",
    "    for i in range(0,len(list(data5.values())[id])):\n",
    "        content5 = re.sub(\"[\\s+\\.\\!\\/_,%^*(+\\\"\\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿ?ã€~@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰ï¼‹ï¼ï½ï¼š]+\",\n",
    "                       \"\",list(data5.values())[id][i])\n",
    "        words5 = jieba.lcut(content5,cut_all=False)\n",
    "        dic5[list(data5.keys())[id]].append(words5)\n",
    "#è¿´åœˆæ–·è©\n",
    "for i in range(0,len(list(data5.keys()))):\n",
    "    dic5[list(data5.keys())[i]] = []\n",
    "for j in range(0,len(list(data5.keys()))):\n",
    "    cutcomment(j)\n",
    "#å­˜å‡ºä¾†\n",
    "f = open('group5_message_word.txt', 'wb')\n",
    "output = pickle.dump(dic5, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#å®šç¾©æ–·è©æ–¹å¼\n",
    "dic6 = {}\n",
    "dic6.update(data6)\n",
    "def cutcomment(id):\n",
    "    for i in range(0,len(list(data6.values())[id])):\n",
    "        content6 = re.sub(\"[\\s+\\.\\!\\/_,%^*(+\\\"\\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿ?ã€~@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰ï¼‹ï¼ï½ï¼š]+\",\n",
    "                       \"\",list(data6.values())[id][i])\n",
    "        words6 = jieba.lcut(content6,cut_all=False)\n",
    "        dic6[list(data6.keys())[id]].append(words6)\n",
    "#è¿´åœˆæ–·è©\n",
    "for i in range(0,len(list(data6.keys()))):\n",
    "    dic6[list(data6.keys())[i]] = []\n",
    "for j in range(0,len(list(data6.keys()))):\n",
    "    cutcomment(j)\n",
    "#å­˜å‡ºä¾†\n",
    "f = open('group6_message_word.txt', 'wb')\n",
    "output = pickle.dump(dic6, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#å®šç¾©æ–·è©æ–¹å¼\n",
    "dic7 = {}\n",
    "dic7.update(data7)\n",
    "def cutcomment(id):\n",
    "    for i in range(0,len(list(data7.values())[id])):\n",
    "        content7 = re.sub(\"[\\s+\\.\\!\\/_,%^*(+\\\"\\']+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿ?ã€~@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰ï¼‹ï¼ï½ï¼š]+\",\n",
    "                       \"\",list(data7.values())[id][i])\n",
    "        words7 = jieba.lcut(content7,cut_all=False)\n",
    "        dic7[list(data7.keys())[id]].append(words7)\n",
    "#è¿´åœˆæ–·è©\n",
    "for i in range(0,len(list(data7.keys()))):\n",
    "    dic7[list(data7.keys())[i]] = []\n",
    "for j in range(0,len(list(data7.keys()))):\n",
    "    cutcomment(j)\n",
    "#å­˜å‡ºä¾†\n",
    "f = open('group7_message_word.txt', 'wb')\n",
    "output = pickle.dump(dic7, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['æ…•å‡¡æƒ³ç•¶ç¶²ç´…',\n",
       " 'burger kingé›å¡Šä¸å¥½åƒ',\n",
       " '\\x08$$$ä¸»æ’­åƒéº¥ç•¶å‹å—',\n",
       " 'é€™å€‹å¥½é…·å–”',\n",
       " 'ç–‘ä¼¼ç”¨å‡¡å“¥é¨™è®š',\n",
       " 'å‡¡å“¥åˆå‡ºç¾äº†',\n",
       " 'å¥½å¥½åƒçš„æ„Ÿè¦º',\n",
       " 'èŠ’æœè˜†è–ˆï¼±ï¼±',\n",
       " 'éŒ¦èå§æœƒå¥½å¤šåœ‹èªè¨€',\n",
       " 'ç¾åœ‹åƒè–¯æ¢',\n",
       " 'è³½çˆ¾ç¶­é›…åƒå•¥',\n",
       " 'å¾ˆåƒè—äººç›´æ’­',\n",
       " 'å¥½high',\n",
       " 'å¥½åƒç¯€ç›®å–”',\n",
       " 'æœ‰å—',\n",
       " 'æ„›çˆ¾è˜­ï¼',\n",
       " 'ç…§ç‰‡è®š',\n",
       " 'å‡¡å“¥åŠ å…¥',\n",
       " 'æ˜¯å‡¡å“¥',\n",
       " 'æ˜¯å–”',\n",
       " 'æˆ‘ä¹Ÿé¤“äº†',\n",
       " 'å°å•Š',\n",
       " 'å¥½å—¨å–”ï½ï½ï½ï½ï½',\n",
       " 'å»£æ±è©±',\n",
       " 'æ˜¯é™³æ€¡æ½”',\n",
       " 'ğŸ¤“ğŸ¤“ğŸ¤“ğŸ¤“ğŸ¤“',\n",
       " '\\U0001f923\\U0001f923\\U0001f923\\U0001f923',\n",
       " 'æ—¥æœ¬é™¤äº†æ‹‰éºµ å…¶ä»–éƒ½é‚„å¥½å§',\n",
       " 'æˆ‘ä»¥ç‚º Momus Chaoåœ¨ç½µé«’è©±',\n",
       " 'æ—¥æœ¬æ‡‰è©²æ²’å•¥æ·»åŠ ç‰©å§',\n",
       " 'EJæœ‰å¼µé–‹çœ¼ç›å ±å—ï¼Ÿï¼‹1',\n",
       " 'å‰å¹³ã„',\n",
       " 'å“‡å—š',\n",
       " 'å¥½ç¹½ç´›',\n",
       " 'æƒ³çœ‹é˜¿å‰',\n",
       " 'æƒ³çœ‹é˜¿å‰again',\n",
       " '$$$å‹•ç‰©é¢±é¢¨åå¯ä»¥èˆ‰ä¾‹å—',\n",
       " 'çœ‹ä¸åˆ°æ©«è»¸',\n",
       " 'é‚„æœ‰æ‰‹èªï¼¸ï¼¤ï¼¤ï¼¤ï¼¤',\n",
       " 'å°ä¸¸å­ç‚ºä»€éº¼æ˜¯ç”·ç”Ÿè²éŸ³ï¼šï¼ˆ',\n",
       " 'å¥½æœ‰äº‹ï¼¸ï¼¤ï¼¤ï¼¤',\n",
       " 'ä½©å¿ƒå¥½çŠ§ç‰²',\n",
       " 'èª°ç”¨æ´ªè€å¸«çš„åç¾©ï¼¸ï¼¤',\n",
       " 'èŠ±è¼ª',\n",
       " '$$$GBæ˜¯å“ªåœ‹',\n",
       " 'å·²ç¶“æ²’æœ‰å›éŸ³ã„Œæƒ¡',\n",
       " 'ç‚ºä»€éº¼æœƒæœ‰å›éŸ³ï¼±ï¼±',\n",
       " 'å–”å–”å–” è‹±åœ‹',\n",
       " 'é‚„æœ‰å›éŸ³å—',\n",
       " 'æ­£ä¹¾åå˜´',\n",
       " 'Væ€ªå®¢',\n",
       " 'æ­£å¦¹ï¼šï¼¤',\n",
       " 'å°ˆæ¥­åˆ†æ',\n",
       " 'ï¼šï¼¤',\n",
       " 'å“‡å—š',\n",
       " 'å“ˆå“ˆå“ˆå“ˆå“ˆ',\n",
       " 'æ—ç§˜æ›¸ä¹Ÿå‡ºç¾äº†ï¼ï¼ï¼ï¼ï¼ï¼',\n",
       " '$$$ä¸çŸ¥é“å‰›å‰›æœ‰æ²’æœ‰æ¼è½\\næˆ‘æƒ³å•è³‡æ–™æ˜¯é–‹æºçš„å—ï¼Ÿï¼Ÿ è¬è¬',\n",
       " 'å“‡å—š å¥½é…·',\n",
       " 'å–”å–”å–” æ·é‹',\n",
       " 'å¤§é©š',\n",
       " 'kenå“¥åˆ°åº•ï¼ï¼',\n",
       " 'åŸä¾†å¦‚æ­¤ï½',\n",
       " 'æ´ªè€å¸«ç¾èº«',\n",
       " 'ï¼¸ï¼¤ï¼¤ï¼¤',\n",
       " 'å¥½é…·çš„åœ–',\n",
       " 'kenå“¥åœ¨å¹¹éº»']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Allison Yeh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['æ…•å‡¡', 'æƒ³ç•¶', 'ç¶²ç´…'],\n",
       " ['burgerking', 'é›å¡Š', 'ä¸', 'å¥½åƒ'],\n",
       " ['\\x08', '$', '$', '$', 'ä¸»æ’­', 'åƒ', 'éº¥ç•¶å‹', 'å—'],\n",
       " ['é€™å€‹', 'å¥½é…·', 'å–”'],\n",
       " ['ç–‘ä¼¼', 'ç”¨å‡¡å“¥', 'é¨™', 'è®š'],\n",
       " ['å‡¡å“¥', 'åˆ', 'å‡ºç¾', 'äº†'],\n",
       " ['å¥½', 'å¥½åƒ', 'çš„', 'æ„Ÿè¦º'],\n",
       " ['èŠ’æœ', 'è˜†è–ˆ', 'ï¼±', 'ï¼±'],\n",
       " ['éŒ¦è', 'å§æœƒ', 'å¥½å¤š', 'åœ‹èª', 'è¨€'],\n",
       " ['ç¾åœ‹', 'åƒ', 'è–¯æ¢'],\n",
       " ['è³½çˆ¾ç¶­é›…', 'åƒ', 'å•¥'],\n",
       " ['å¾ˆ', 'åƒ', 'è—äºº', 'ç›´æ’­'],\n",
       " ['å¥½', 'high'],\n",
       " ['å¥½åƒ', 'ç¯€ç›®', 'å–”'],\n",
       " ['æœ‰', 'å—'],\n",
       " ['æ„›çˆ¾è˜­'],\n",
       " ['ç…§ç‰‡', 'è®š'],\n",
       " ['å‡¡å“¥', 'åŠ å…¥'],\n",
       " ['æ˜¯', 'å‡¡å“¥'],\n",
       " ['æ˜¯', 'å–”'],\n",
       " ['æˆ‘', 'ä¹Ÿ', 'é¤“', 'äº†'],\n",
       " ['å°', 'å•Š'],\n",
       " ['å¥½', 'å—¨', 'å–”'],\n",
       " ['å»£æ±è©±'],\n",
       " ['æ˜¯', 'é™³', 'æ€¡æ½”'],\n",
       " ['ğŸ¤“', 'ğŸ¤“', 'ğŸ¤“', 'ğŸ¤“', 'ğŸ¤“'],\n",
       " ['\\U0001f923', '\\U0001f923', '\\U0001f923', '\\U0001f923'],\n",
       " ['æ—¥æœ¬', 'é™¤äº†', 'æ‹‰', 'éºµ', 'å…¶ä»–', 'éƒ½', 'é‚„å¥½', 'å§'],\n",
       " ['æˆ‘', 'ä»¥', 'ç‚º', 'MomusChao', 'åœ¨', 'ç½µ', 'é«’', 'è©±'],\n",
       " ['æ—¥æœ¬', 'æ‡‰è©²', 'æ²’', 'å•¥', 'æ·»åŠ ç‰©', 'å§'],\n",
       " ['EJ', 'æœ‰', 'å¼µé–‹', 'çœ¼ç›', 'å ±', 'å—', '1'],\n",
       " ['å‰å¹³', 'ã„'],\n",
       " ['å“‡', 'å—š'],\n",
       " ['å¥½ç¹½ç´›'],\n",
       " ['æƒ³', 'çœ‹', 'é˜¿å‰'],\n",
       " ['æƒ³', 'çœ‹', 'é˜¿å‰', 'again'],\n",
       " ['$', '$', '$', 'å‹•ç‰©', 'é¢±', 'é¢¨å', 'å¯ä»¥', 'èˆ‰ä¾‹', 'å—'],\n",
       " ['çœ‹ä¸åˆ°', 'æ©«è»¸'],\n",
       " ['é‚„æœ‰', 'æ‰‹èª', 'ï¼¸', 'ï¼¤', 'ï¼¤', 'ï¼¤', 'ï¼¤'],\n",
       " ['å°ä¸¸å­', 'ç‚º', 'ä»€éº¼', 'æ˜¯', 'ç”·ç”Ÿ', 'è²éŸ³'],\n",
       " ['å¥½', 'æœ‰äº‹', 'ï¼¸', 'ï¼¤', 'ï¼¤', 'ï¼¤'],\n",
       " ['ä½©å¿ƒ', 'å¥½', 'çŠ§ç‰²'],\n",
       " ['èª°', 'ç”¨', 'æ´ªè€å¸«', 'çš„', 'åç¾©', 'ï¼¸', 'ï¼¤'],\n",
       " ['èŠ±è¼ª'],\n",
       " ['$', '$', '$', 'GB', 'æ˜¯', 'å“ªåœ‹'],\n",
       " ['å·²ç¶“', 'æ²’æœ‰', 'å›éŸ³', 'ã„Œ', 'æƒ¡'],\n",
       " ['ç‚º', 'ä»€éº¼', 'æœƒ', 'æœ‰', 'å›éŸ³', 'ï¼±', 'ï¼±'],\n",
       " ['å–”', 'å–”', 'å–”', 'è‹±åœ‹'],\n",
       " ['é‚„æœ‰', 'å›éŸ³', 'å—'],\n",
       " ['æ­£ä¹¾', 'åå˜´'],\n",
       " ['V', 'æ€ªå®¢'],\n",
       " ['æ­£å¦¹', 'ï¼¤'],\n",
       " ['å°ˆæ¥­', 'åˆ†æ'],\n",
       " ['ï¼¤'],\n",
       " ['å“‡', 'å—š'],\n",
       " ['å“ˆå“ˆå“ˆ', 'å“ˆå“ˆ'],\n",
       " ['æ—ç§˜', 'æ›¸', 'ä¹Ÿ', 'å‡ºç¾', 'äº†'],\n",
       " ['$',\n",
       "  '$',\n",
       "  '$',\n",
       "  'ä¸',\n",
       "  'çŸ¥é“',\n",
       "  'å‰›å‰›',\n",
       "  'æœ‰',\n",
       "  'æ²’',\n",
       "  'æœ‰',\n",
       "  'æ¼',\n",
       "  'è½',\n",
       "  'æˆ‘',\n",
       "  'æƒ³',\n",
       "  'å•è³‡æ–™',\n",
       "  'æ˜¯',\n",
       "  'é–‹æº',\n",
       "  'çš„',\n",
       "  'å—',\n",
       "  'è¬è¬'],\n",
       " ['å“‡', 'å—š', 'å¥½é…·'],\n",
       " ['å–”', 'å–”', 'å–”', 'æ·é‹'],\n",
       " ['å¤§é©š'],\n",
       " ['ken', 'å“¥', 'åˆ°åº•'],\n",
       " ['åŸä¾†', 'å¦‚æ­¤'],\n",
       " ['æ´ªè€å¸«', 'ç¾èº«'],\n",
       " ['ï¼¸', 'ï¼¤', 'ï¼¤', 'ï¼¤'],\n",
       " ['å¥½é…·', 'çš„', 'åœ–'],\n",
       " ['ken', 'å“¥', 'åœ¨', 'å¹¹éº»']]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['Allison Yeh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
